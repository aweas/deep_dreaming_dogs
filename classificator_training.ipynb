{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import skimage.transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from network import abstract_network\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pictures(directory='train/'):\n",
    "    with open('files_list.txt') as f:\n",
    "        files_list = f.readlines()\n",
    "    files_list = [(directory+i.strip()) for i in files_list]\n",
    "    return files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "files_list = read_pictures('resized_train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_img(img):\n",
    "#     return skimage.transform.resize(img, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dataset(preprocess = True, files_num=1000, random=False):\n",
    "#     X = np.empty((files_num, *input_shape), dtype=np.float32)\n",
    "#     y = np.empty((files_num, 2), dtype=np.uint8)\n",
    "    \n",
    "#     if random:\n",
    "#         files_to_read = np.random.choice(files_list, files_num)\n",
    "#     else:\n",
    "#         files_to_read = files_list[:files_num]\n",
    "        \n",
    "#     if preprocess:\n",
    "#         operation = lambda x: preprocess_img(cv2.imread(x))[:,:,::-1]\n",
    "#     else:\n",
    "#         operation = lambda x: cv2.imread(x)[:,:,::-1]\n",
    "        \n",
    "#     for num, i in enumerate(tqdm.tqdm(files_to_read)):\n",
    "#         X[num] = operation(i)\n",
    "            \n",
    "#         if 'cat' in i:\n",
    "#             y[num] = [1, 0]\n",
    "#         else:\n",
    "#             y[num] = [0, 1]\n",
    "#     return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_preprocessed_images(images):\n",
    "#     for i, name in tqdm.tqdm(zip(images, files_list)):\n",
    "#         plt.imsave(f'preprocessed_images/{name.split(\"/\")[-1]}', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = get_dataset(preprocess=True, files_num=25000, random=False)\n",
    "# X = X/np.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_preprocessed_images(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(files_list, test_size=0.3)\n",
    "\n",
    "# Free memory\n",
    "# del X\n",
    "# del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.subplot(121)\n",
    "# plt.imshow(X_train[1]);\n",
    "# plt.subplot(122)\n",
    "# plt.imshow(X_train[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_network(abstract_network):       \n",
    "    def _inference(self):\n",
    "        inp = self.input\n",
    "        with tf.name_scope('classificator'):\n",
    "            with tf.name_scope('convolution'):\n",
    "                layer = tf.layers.conv2d(inp, 64, 3, activation=tf.nn.relu)\n",
    "                layer = tf.layers.max_pooling2d(layer, pool_size=3, strides=2)\n",
    "        \n",
    "                layer = tf.layers.conv2d(layer, 64, 3, activation=tf.nn.relu)\n",
    "                layer = tf.layers.max_pooling2d(layer, pool_size=3, strides=2)\n",
    "                layer = tf.nn.dropout(layer, self.dropout_prob)\n",
    "                \n",
    "                layer = tf.layers.conv2d(layer, 64, 3, activation=tf.nn.relu)\n",
    "                layer = tf.layers.max_pooling2d(layer, pool_size=3, strides=2)\n",
    "                \n",
    "                layer = tf.layers.conv2d(layer, 64, 3, activation=tf.nn.relu, padding='same')\n",
    "                layer = tf.layers.max_pooling2d(layer, pool_size=3, strides=2)\n",
    "                \n",
    "                layer = tf.layers.conv2d(layer, 64, 3, activation=tf.nn.relu, padding='same')\n",
    "                layer = tf.layers.max_pooling2d(layer, pool_size=3, strides=2)\n",
    "                layer = tf.nn.dropout(layer, self.dropout_prob)\n",
    "                \n",
    "#                 layer = tf.layers.conv2d(layer, 16, , activation=tf.nn.relu)\n",
    "#                 layer = tf.layers.max_pooling2d(layer, pool_size=3, strides=2)\n",
    "                \n",
    "                layer = tf.layers.flatten(layer)\n",
    "\n",
    "            with tf.name_scope('dense'):\n",
    "                layer = tf.layers.dense(layer, 1024, activation=tf.nn.relu)\n",
    "                layer = tf.nn.dropout(layer, self.dropout_prob)\n",
    "                layer = tf.layers.dense(layer, 512, activation=tf.nn.relu)\n",
    "                layer = tf.layers.batch_normalization(layer)\n",
    "                layer = tf.layers.dense(layer, 256, activation=tf.nn.relu)\n",
    "                layer = tf.layers.dense(layer, 128, activation=tf.nn.relu)\n",
    "#                 layer = tf.layers.batch_normalization(layer)\n",
    "                layer = tf.layers.dense(layer, 2, activation=tf.nn.softmax)\n",
    "\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50% of training is class 0\n",
      "49% of test is class 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:43<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 61% \tTraining loss: 0.6900765608697045 \t Training accuracy: 52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:40<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 63% \tTraining loss: 0.6272738519376214 \t Training accuracy: 64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:40<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 73% \tTraining loss: 0.5933842174980769 \t Training accuracy: 69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:40<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 74% \tTraining loss: 0.560240742716476 \t Training accuracy: 73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:40<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 78% \tTraining loss: 0.5327748271235586 \t Training accuracy: 76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:40<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 80% \tTraining loss: 0.5082223443654329 \t Training accuracy: 79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:40<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 83% \tTraining loss: 0.4898830065979574 \t Training accuracy: 81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:40<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 85% \tTraining loss: 0.4795674428235002 \t Training accuracy: 82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:40<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 84% \tTraining loss: 0.47527281156856643 \t Training accuracy: 82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:40<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 86% \tTraining loss: 0.4648713690303539 \t Training accuracy: 83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:40<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 87% \tTraining loss: 0.4554256807713615 \t Training accuracy: 84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:40<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 87% \tTraining loss: 0.46040834225442295 \t Training accuracy: 84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:40<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 86% \tTraining loss: 0.4412205737002575 \t Training accuracy: 86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:40<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 87% \tTraining loss: 0.4362156576048718 \t Training accuracy: 87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 274/274 [00:40<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 88% \tTraining loss: 0.4362049980537735 \t Training accuracy: 86%\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "network = cnn_network(input_shape)\n",
    "network.set_training_data(X_train, X_test)\n",
    "network.training(batch_size=128, epochs=15, iter_before_validation=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len([op.name for op in tf.get_default_graph().get_operations() if 'output' in op.name or 'features' in op.name]) == 2\n",
    "assert len([op.name for op in tf.get_default_graph().get_operations() if 'cnn_' in op.name]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.save_model('saved_model/classifier_256x256_full.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
